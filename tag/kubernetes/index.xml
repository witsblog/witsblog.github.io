<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes | Wit's Blog</title><link>https://witsblog.github.io/tag/kubernetes/</link><atom:link href="https://witsblog.github.io/tag/kubernetes/index.xml" rel="self" type="application/rss+xml"/><description>Kubernetes</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 04 Feb 2023 00:00:00 +0000</lastBuildDate><image><url>https://witsblog.github.io/media/icon_hu66cf44b0d2eab4dae9de00f68d847da7_1567_512x512_fill_lanczos_center_3.png</url><title>Kubernetes</title><link>https://witsblog.github.io/tag/kubernetes/</link></image><item><title>Ever Wonder How Kubernetes CPU Limit Can Be a Fraction?</title><link>https://witsblog.github.io/post/021_k8s_cpu_limit/</link><pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate><guid>https://witsblog.github.io/post/021_k8s_cpu_limit/</guid><description>&lt;p>As a software engineer at a big tech company, I usually rely on an infrastructure team to provide deployment tools for us. While convenient, this, I realized, is a missed learning opportunity.&lt;/p>
&lt;p>One of the things that I have been curious about all along is&lt;/p>
&lt;ul>
&lt;li>How does Kubernetes limits CPU and memory resource?&lt;/li>
&lt;li>How can CPU allocation even be a fraction and less than 1?&lt;/li>
&lt;/ul>
&lt;p>Curiosity got the better of me, and I decided to explore how Kubernetes handles this task.&lt;/p>
&lt;br>
&lt;h2 id="requests-and-limit">Requests and Limit&lt;/h2>
&lt;p>When we deploy our service, we can specify the resource &lt;code>request&lt;/code> and &lt;code>limit&lt;/code>. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">resources&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">requests&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">memory&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s2">&amp;#34;256Mi&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">cpu&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s2">&amp;#34;250m&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">limits&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">memory&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s2">&amp;#34;768Mi&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">cpu&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s2">&amp;#34;750m&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Basically,&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CPU&lt;/p>
&lt;ul>
&lt;li>&lt;code>request&lt;/code>
&lt;ul>
&lt;li>Used during the Pod scheduling. When Kubernetes scheduler selects a node for the Pod to run on, it ensures that the &lt;code>request&lt;/code> does not exceed the capacity of the node.&lt;/li>
&lt;li>The workloads are allocated CPU time proportionally to the &lt;code>request&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>limit&lt;/code>
&lt;ul>
&lt;li>This sets the hard limit during each &lt;em>&lt;strong>scheduling interval&lt;/strong>&lt;/em>. If the execution time exceeds, the OS kernel will throttle.
&lt;blockquote>
&lt;p>The CPU limit defines a hard ceiling on how much CPU time that the container can use. During each scheduling interval (time slice), the Linux kernel checks to see if this limit is exceeded; if so, the kernel waits before allowing that cgroup to resume execution.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Memory&lt;/p>
&lt;ul>
&lt;li>&lt;code>request&lt;/code>
&lt;ul>
&lt;li>Similar to CPU &lt;code>request&lt;/code>, this is used during the Pod scheduling.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>limit&lt;/code>
&lt;ul>
&lt;li>The effect of this is such that, if the container tries to allocate more memory than this limit, it will get &lt;em>OOM (out of memory)&lt;/em> error.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://witsblog.github.io/post/020_k8s_cpu_limit/featured.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;br>
&lt;h2 id="cfs-bandwidth-control">CFS Bandwidth Control&lt;/h2>
&lt;h3 id="the-mechanism">The Mechanism&lt;/h3>
&lt;blockquote>
&lt;p>How does Kubernetes limit the CPU?&lt;/p>
&lt;/blockquote>
&lt;p>Kubernetes limits the resource by means of the &lt;a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/cgroups.html" target="_blank" rel="noopener">cgroup&lt;/a> concept in the Linux kernel.&lt;/p>
&lt;p>For CPU &lt;code>limit&lt;/code>, this is done by the &lt;a href="https://www.kernel.org/doc/html/latest/scheduler/sched-bwc.html" target="_blank" rel="noopener">CFS Bandwidth Control&lt;/a> in the Linux kernel. The bandwidth allowed for a group is specified using a &lt;strong>quota&lt;/strong> and &lt;strong>period&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>For cgroup v1, these settings are located in &lt;code>/sys/fs/cgroup/cpu,cpuacct/&lt;/code>, where the quota and period are in &lt;code>cpu.cfs_quota_us&lt;/code> and &lt;code>cpu.cfs_period_us&lt;/code> respectively.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://witsblog.github.io/images/post/021/02.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For cgroup v2, these settings are in &lt;code>/sys/fs/cgroup/cpu.max&lt;/code>, in the following format&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">&amp;lt;quota&amp;gt; &amp;lt;preiod&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://witsblog.github.io/images/post/021/03.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Essentially&lt;/p>
&lt;ul>
&lt;li>Within each given &lt;strong>period&lt;/strong> (
${\mu}s$), a task group is allocated up to &lt;strong>quota&lt;/strong> (
${\mu} s$) of CPU time.&lt;/li>
&lt;li>If the &lt;strong>quota&lt;/strong> is fully utilized before the &lt;strong>period&lt;/strong> ends, any additional requests for CPU time will result in those threads in the group being throttled. They won&amp;rsquo;t be able to run again until the quota is replenished in the next &lt;strong>period&lt;/strong>.&lt;/li>
&lt;li>The allocated &lt;strong>quota&lt;/strong> is divided and assigned to per-CPU run queues in &lt;strong>slice&lt;/strong> as threads within the cgroup become runnable. This is a system wide setting in &lt;code>/proc/sys/kernel/sched_cfs_bandwidth_slice_us&lt;/code> with default value = 5 ms.&lt;/li>
&lt;li>Unused quota is tracked globally and is refreshed at each period boundary.&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>So how can CPU &lt;code>limit&lt;/code> be a fraction? How can it be less than 1?&lt;/p>
&lt;/blockquote>
&lt;p>Let&amp;rsquo;s visualize. Assume a task takes 125 ms to process. This is what would happen if we &lt;strong>don&amp;rsquo;t&lt;/strong> set the CPU &lt;code>limit&lt;/code>:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://witsblog.github.io/images/post/021/04.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>If we set CPU &lt;code>limit&lt;/code> to &lt;code>0.25&lt;/code> CPU or &lt;code>250m&lt;/code> CPU, Kubernetes would set &lt;strong>quota&lt;/strong>
$= 0.25 \times 100 = 25$ ms. So this means that within a (default) 100 ms &lt;strong>period&lt;/strong>, the task can use up 25 ms, and it will finish at 425 ms (instead of 125 ms, what a surprise!):&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://witsblog.github.io/images/post/021/05.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>If we look at the &lt;code>cpu.stat&lt;/code>, we would probably see:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Statistics&lt;/th>
&lt;th>Value&lt;/th>
&lt;th>Meaning&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>nr_periods&lt;/code>&lt;/td>
&lt;td>5&lt;/td>
&lt;td>Number of intervals that have elapsed.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>nr_throttled&lt;/code>&lt;/td>
&lt;td>4&lt;/td>
&lt;td>Number of times the group has been throttled.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>throttled_usec&lt;/code>&lt;/td>
&lt;td>300000&lt;/td>
&lt;td>The total time duration for which the group have been throttled.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>From the following calculation, the throttled rate would be ~80% !&lt;/p>
$$throttled \space \% = \frac{nr\_throttled}{nr\_periods}$$
&lt;h3 id="more-is-revealed-in-the-kernel-code">More is Revealed in the Kernel Code&lt;/h3>
&lt;blockquote>
&lt;p>What if the CPU &lt;code>limit&lt;/code> is greater than 1? This means the &lt;strong>quota&lt;/strong> would be greater than the &lt;strong>period&lt;/strong>. How can it still be throttled?&lt;/p>
&lt;/blockquote>
&lt;p>In a real system, there are multiple CPU cores. The Linux kernel tracks the quota from the &lt;strong>global pool&lt;/strong> rather than on a per-CPU basis. So even though the time used in each period per CPU core cannot exceed the &lt;strong>period&lt;/strong> itself, the total sum of &lt;strong>quota&lt;/strong> across multiple cores can be greater than the period. This can result in throttling:&lt;/p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://witsblog.github.io/images/post/021/06.webp" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;p>If we look at the kernel &lt;a href="https://github.com/torvalds/linux" target="_blank" rel="noopener">code&lt;/a>, we would actaully see it:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">static&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">__assign_cfs_rq_runtime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="n">cfs_bandwidth&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">struct&lt;/span> &lt;span class="n">cfs_rq&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">cfs_rq&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">u64&lt;/span> &lt;span class="n">target_runtime&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">u64&lt;/span> &lt;span class="n">min_amount&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">amount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">lockdep_assert_held&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">lock&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">min_amount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">target_runtime&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">cfs_rq&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime_remaining&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">quota&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">RUNTIME_INF&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">amount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">min_amount&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">start_cfs_bandwidth&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">amount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">min_amount&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="n">amount&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="c1">// &amp;lt;---------- Take from the global pool
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">idle&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cfs_rq&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime_remaining&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">amount&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">cfs_rq&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime_remaining&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">static&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">assign_cfs_rq_runtime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="n">cfs_rq&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">cfs_rq&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">struct&lt;/span> &lt;span class="n">cfs_bandwidth&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">cfs_b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tg_cfs_bandwidth&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cfs_rq&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">tg&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">int&lt;/span> &lt;span class="n">ret&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">raw_spin_lock&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">lock&lt;/span>&lt;span class="p">);&lt;/span> &lt;span class="c1">// &amp;lt;---------- Lock
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="n">ret&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">__assign_cfs_rq_runtime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cfs_rq&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nf">sched_cfs_bandwidth_slice&lt;/span>&lt;span class="p">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">raw_spin_unlock&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">lock&lt;/span>&lt;span class="p">);&lt;/span> &lt;span class="c1">// &amp;lt;---------- Unlock
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">ret&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And from the document&lt;/p>
&lt;blockquote>
&lt;p>all but 1ms of the slice may be returned to the global pool if all threads on that cpu become unrunnable. This is configured at compile time by the &lt;code>min_cfs_rq_runtime&lt;/code> variable. This is a performance tweak that helps prevent added contention on the global lock.&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">__return_cfs_rq_runtime&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="n">cfs_rq&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">cfs_rq&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">struct&lt;/span> &lt;span class="n">cfs_bandwidth&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">cfs_b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tg_cfs_bandwidth&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cfs_rq&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">tg&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">s64&lt;/span> &lt;span class="n">slack_runtime&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cfs_rq&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime_remaining&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">min_cfs_rq_runtime&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">slack_runtime&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">raw_spin_lock&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">lock&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">quota&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="n">RUNTIME_INF&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">slack_runtime&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="c1">// &amp;lt;---------- Return to the global pool
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* we are under rq-&amp;gt;lock, defer unthrottling using a timer */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">sched_cfs_bandwidth_slice&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">!&lt;/span>&lt;span class="nf">list_empty&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">throttled_cfs_rq&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">start_cfs_slack_bandwidth&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">raw_spin_unlock&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">cfs_b&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">lock&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* even if it&amp;#39;s not valid for return we don&amp;#39;t want to try again */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cfs_rq&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">runtime_remaining&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="n">slack_runtime&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="a-side-note-about-spinlock">A Side Note About Spinlock&lt;/h3>
&lt;p>What&amp;rsquo;s intersting while reading the kernel code is that, it uses &lt;strong>spinlock&lt;/strong> a lot.&lt;/p>
&lt;p>I believe this is for a performance reason.&lt;/p>
&lt;p>Unlike &lt;strong>mutex locks&lt;/strong>, which put the waiting thread to sleep, &lt;strong>spinlocks&lt;/strong> make the thread continuously &amp;ldquo;spin&amp;rdquo; until the lock is available. This approach is efficient where critical sections are expected to be short as it avoids the overhead of sleeping and waking threads.&lt;/p>
&lt;br>
&lt;h2 id="should-we-set-the-cpu-limit">Should We Set the CPU Limit?&lt;/h2>
&lt;br>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">This is why I always advise:&lt;br>&lt;br>1) Always set memory limit == request&lt;br>2) Never set CPU limit&lt;br>&lt;br>(for locally adjusted values of &amp;quot;always&amp;quot; and &amp;quot;never&amp;quot;)&lt;/p>&amp;mdash; Tim Hockin (thockin.yaml) (@thockin) &lt;a href="https://twitter.com/thockin/status/1134193838841401345?ref_src=twsrc%5Etfw">May 30, 2019&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>I think it depends a lot by use case.&lt;/p>
&lt;ul>
&lt;li>If we want the performance, maybe avoid setting the CPU limit.&lt;/li>
&lt;li>But in some use case where we want &lt;em>consistency&lt;/em>, or &lt;em>reproducable&lt;/em> performance like load testing, we may want to set the limit.&lt;/li>
&lt;/ul>
&lt;br>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/cgroups.html" target="_blank" rel="noopener">https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/cgroups.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/torvalds/linux" target="_blank" rel="noopener">https://github.com/torvalds/linux&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.reddit.com/r/kubernetes/comments/wgztqh/for_the_love_of_god_stop_using_cpu_limits_on/?rdt=51634" target="_blank" rel="noopener">https://www.reddit.com/r/kubernetes/comments/wgztqh/for_the_love_of_god_stop_using_cpu_limits_on/?rdt=51634&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.reddit.com/r/kubernetes/comments/12he7aa/cpu_limits/" target="_blank" rel="noopener">https://www.reddit.com/r/kubernetes/comments/12he7aa/cpu_limits/&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>