[{"authors":null,"categories":null,"content":"I am currently a Machine Learning Engineer at Agoda. My current work revolves around building data pipelines and real-time machine learning pipelines.\nI was previously a Robotics Software Engineer at AI \u0026amp; Robotics Ventures, a start-up from a petroleum company called PTTEP.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am currently a Machine Learning Engineer at Agoda. My current work revolves around building data pipelines and real-time machine learning pipelines.\nI was previously a Robotics Software Engineer at AI \u0026 Robotics Ventures, a start-up from a petroleum company called PTTEP.","tags":null,"title":"Wit Sirawit","type":"authors"},{"authors":null,"categories":null,"content":"\nBaseline Impl v2 ","date":1739318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741219200,"objectID":"e4a311b8a5772f6fa631efc982d36cd5","permalink":"https://witsblog.github.io/post/056_lob/","publishdate":"2025-02-12T00:00:00Z","relpermalink":"/post/056_lob/","section":"post","summary":"\nBaseline Impl v2 ","tags":["C/C++","Trading"],"title":"Limit Order Book Construction","type":"post"},{"authors":null,"categories":null,"content":"ML Pipeline Automation Google has a very interesting article written about the level of automation in ML pipeline.\nLevel 0 Level 2 MLOps – Every Team is Doing Things Differently In our team, we are pretty close to the level 2 as described by Google in their article. While we’ve adopted many of the principles described, we’ve made specific adjustments to better fit our use case.\nKey Differences\nVelocity Tool\nWe developed a custom Velocity Tool to help business and data science teams iterate quickly on ideas and features. By standardizing the entire pipeline, we can automate all the tasks. Inference Integration\nWe don’t run model inference as a separate service to avoid network latency caused by additional service calls. Instead, we write our own runtime that operates within the same backend service process. The Velocity Tool Typically, data scientists manually handle the model development steps:\nData Preparation Model Training Model Evaluation But imagine in a team where we have common business metrics that we measure and monitor consistenly, we can enforce these metrics as part of the model evaluation stage and streamline the process. This way, even business users can focus solely on providing features, while the tool automates the rest. Plus, we often win by iterating on features more than by changing the models. So the Velocity Tool would be beneficial.\nAnother problem is that: training (or backtesting) doesn’t mean the model would perform correctly and with a live production data. So we extend the ML pipeline by adding 2 stages:\nSandbox Stage This stage checks that the model performs correctly and doesn’t violate business rules. We can think of this as another form of backtesting. (We replay historical data through the model and collect metrics.) A/B Experimentation Stage This stage actually deploys and runs a model in production, using a small allocated traffic. Once the decision is made, users can select to deploy a model in production. Typically there are no code changes, so we can automate the deployment as well.\nBut how do we know if the model is performing well in production?\nFor tasks where data can be labeled, it’s straignforward to sample the collected data, have a process to manually label it, and therefore measure model’s performance directly. For tasks where there is no direct label, we have to use some metric as a proxy. In some other tasks, we have to frame the problem as a reinforcement learning. Our team is dealing with the later 2 cases, and it’s been a challenge for us to monitor the model performance.\nReferences https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning https://aws.amazon.com/what-is/mlops/ ","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711497600,"objectID":"4b1a395f408800127daca6353e3a44d1","permalink":"https://witsblog.github.io/post/045_mlops_velocity/","publishdate":"2024-03-27T00:00:00Z","relpermalink":"/post/045_mlops_velocity/","section":"post","summary":"ML Pipeline Automation Google has a very interesting article written about the level of automation in ML pipeline.\nLevel 0 Level 2 MLOps – Every Team is Doing Things Differently In our team, we are pretty close to the level 2 as described by Google in their article.","tags":["MLOps","Platform","Data Engineering"],"title":"MLOps Velocity Tool","type":"post"},{"authors":null,"categories":null,"content":"In the world of e-commerce, hundreds of pricing strategies or campaigns are being run simultaneously. But how do these campaigns get validated and tested before rolling out to the users? – Experimentation\nExperimentation allows teams to test and validate ideas quickly, from frontend changes to backend logic changes. It allows us to experiment with different variables and measure their impact.\nIn this blog post, let’s take “pricing strategies” as an example.\nRequirements Business users should be able to create and manage pricing campaigns. Campaigns should target specific user segments (e.g., mobile users, users from specific regions). The campaign \u0026amp; experimentation process needs an approval process. Real-time monitoring is crucial to pause campaigns if negative impacts are detected. Functional Requirements\nInternal UI tool for managing campaigns \u0026amp; experiments. Support for tartgeting user segments. Support different types of allocation strategies (e.g., by user ID, device ID, or time-based). Real-time data collection, monitoring, and analysis. Non-functional Requirements\nScalability to handle large data sets and high traffic. High availability. The platform must remain operational, as downtime could disrupt the variant allocation process and skew analysis results. Low latency for real-time response Campaigns, Allocation, \u0026amp; Experimentation Campaign is usually a business rule (or it can be a machine learning model rule) that applies certain pricing strategies. The campaign should be able to target specific user segments, for example, users from mobile device, users browsing from Singapore, etc.\nIn A/B testing, we create an experiment with 2 groups (variants):\nControl group (A) This group experiences the standard behavior, as same as others not targetted by the experiment. Experimental group (B) This group experiences a special treatment. By comparing business metrics across both groups, we can assess the experiment’s impact.\nBut how do we assign users to variants? This process is called allocation. Given an incoming request with context information, we assign the request to either variant A or B. Depending on the experiment’s needs, different allocation strategy can be used.\nHigh-Level Architecture Integrating Experiments in the Code To integrate an experiment in the code, it typically looks like this:\nrequest = # ... ctx = get_context(request) # Get additional contexts if other_condition and experiment_client.determine_variant(ctx, \u0026#34;EXPERIMENT-ID\u0026#34;) == \u0026#34;B\u0026#34;: plan_b() # B, Experimental group else: plan_a() # A, Control group However, in pricing strategies where hundreds of campaigns may be running simultaneously, it’s a little more complicated than this.\nWhen a request comes in, we first need to identify all the relevant experiments the request is part of (within the targeted segment). Once we know the experiments, we can retrieve the associated campaigns and apply the appropriate pricing strategies defined by the campaigns.\nThis typically involves a rule engine that evaluates the request’s context to determine the relevant experiments. To maintain real-time performance, heavy caching is required—running the rule engine for every single request would introduce significant latency.\nReferences ","date":1705104e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705104e3,"objectID":"c0899b600303c4ef8f8835010f5ddecd","permalink":"https://witsblog.github.io/post/038_pricing_experiment/","publishdate":"2024-01-13T00:00:00Z","relpermalink":"/post/038_pricing_experiment/","section":"post","summary":"In the world of e-commerce, hundreds of pricing strategies or campaigns are being run simultaneously. But how do these campaigns get validated and tested before rolling out to the users? – Experimentation","tags":["Platform","Data Engineering"],"title":"Pricing Experimentation","type":"post"},{"authors":null,"categories":null,"content":"Why? We want to identify any performance degradation before merging code changes into the production environment. Imagine there is a pull request changing some critical logic in the code in a way that increases latency of a backend service by a lot, and this is detected after deployed to the production!\nThe Testing Setup So the basic idea of performance regresssion test is to compare the performance between 2 instances of a backend application; 1 from the baseline (curerntly in production build) and another from the candidate build triggered by a pull request (PR) or a merge request (MR).\nWe also want to ensure the fairness of the test, so the baseline and the candidate versions will be deployed in isolated environment. For this, Kubernetes CPU Limit can be used.\nWe can also use tools like k6 to run the performance test.\nThe .gitlab-ci.yml stages: # ... - docker - manual # ... app_docker: stage: docker script: # Build docker image artifacts: paths: # ... performance_regression_test: stage: manual extends: # ... allow_failure: true needs: - job: app_docker variables: # ... trigger: include: - local: .ci/pipelinees/performance_test/pipeline.yaml strategy: depend resource_group: # ... # .ci/pipelinees/performance_test/pipeline.yaml stages: - test setup # Prepare sample requests, build test runner, deploy baseline \u0026amp; candidate to Kubernetes - perf test # Run the perf test by firing requests to the baseline \u0026amp; candidate - cleanup # Clean up the Kubernetes resource - analyze # Analyze the result, workflow: rules: - if: $CI_MERGE_REQUEST_ID - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH deploy_baseline: stage: test setup # ... deploy_candidate: stage: test setup # ... perf_test_baseline: stage: perf test # ... perf_test_candidate: stage: perf test # ... cleanup_baseline: stage: cleanup # ... cleanup_candidate: stage: cleanup # ... analyze_result: stage: analyze script: # Analyze the result References https://grafana.com/blog/2021/01/27/k6-vs-jmeter-comparison/ ","date":1702684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702684800,"objectID":"cf4a63da66b90cd099ff40e2d3378b35","permalink":"https://witsblog.github.io/post/033_performance_ci/","publishdate":"2023-12-16T00:00:00Z","relpermalink":"/post/033_performance_ci/","section":"post","summary":"Why? We want to identify any performance degradation before merging code changes into the production environment. Imagine there is a pull request changing some critical logic in the code in a way that increases latency of a backend service by a lot, and this is detected after deployed to the production!","tags":["Platform","Data Engineering"],"title":"Detecting Performance Degradation in CI/CD Pipeline","type":"post"},{"authors":null,"categories":null,"content":"I’ve long believed that reader-writer locks would outperform mutexes in scenarios with multiple readers and occasional writers. It seemes intuitive: allowing concurrent reads while ensuring exclusive writes should, in theory, optimize performance.\nSo, is a reader-writer lock better than a mutex? It depends!\nI decided to write a small performance test for this. And the initial results were not what I expected at all—they were quite the opposite and very surprising. The mutex outperforms a reader-writer lock!? How can this be?\nI haven’t yet pinpointed the exact reasons, but I hope to dive deeper into this later.\nTest Design In this experiment, I aim to evaluate the contention performance of an object implementing the following interface. Multiple threads will concurrently call read and update methods, and we will measure the throughput of reads and writes.\nclass MyObject { public: virtual int read(std::array\u0026lt;int, 2\u0026gt;\u0026amp; coordinates) = 0; virtual int update(int dx, int dy) = 0; virtual ~MyObject() = default; }; Mutex The std::mutex class is a synchronization primitive that can be used to protect shared data from being simultaneously accessed by multiple threads.\nThe std::lock_guard is a template class that provides a convenient RAII (Resource Acquisition Is Initialization) mechanism for managing ownership of a mutex.\nIn this implementation, we use std::lock_guard to get exclusive access to the lock mutex_ for both read and update operation. This means that only one thread can access or modify x_ and y_ at any given time.\n// SynchronizedObject.h -------------------------------------------------------- class SynchronizedObject : public MyObject { public: int read(std::array\u0026lt;int, 2\u0026gt;\u0026amp; coordinates) override; int update(int dx, int dy) override; private: std::mutex mutex_; int x_ = 0; int y_ = 0; }; // SynchronizedObject.cpp ------------------------------------------------------ int SynchronizedObject::read(std::array\u0026lt;int, 2\u0026gt;\u0026amp; coordinates) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mutex_); coordinates[0] = x_; coordinates[1] = y_; return 1; } int SynchronizedObject::update(int dx, int dy) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mutex_); x_ += dx; y_ += dy; return 1; } Reader-Writer Lock In this implementation, we use std::shared_mutex instead. This is the documentation:\nShared mutexes are especially useful when shared data can be safely read by any number of threads simultaneously, but a thread may only write the same data when no other thread is reading or writing at the same time.\n// ReadWriteLockObject.h ------------------------------------------------------- class ReadWriteLockObject : public MyObject { public: int read(std::array\u0026lt;int, 2\u0026gt;\u0026amp; coordinates) override; int update(int xDelta, int yDelta) override; private: std::shared_mutex mutex_; // Shared! int x_ = 0; int y_ = 0; }; // ReadWriteLockObject.cpp ----------------------------------------------------- int ReadWriteLockObject::read(std::array\u0026lt;int, 2\u0026gt;\u0026amp; coordinates) { std::shared_lock lock(mutex_); // Multiple threads/readers can read coordinates[0] = x_; coordinates[1] = y_; return 1; } int ReadWriteLockObject::update(int dx, int dy) { std::lock_guard lock(mutex_); // Only one thread/writer can update x_ += dx; y_ += dy; return 1; } The use of std::shared_lock in the read operation allows multiple threads to enter this code section. So multiple threads trying to read won’t contend each other.\nInitial Results What a surprising result. In the above settings, the mutexs outperform reader-writer locks!?\nWhat’s wrong? If this is the case, why the invent of reader-writer lock at all?\nThe Reason After spending some time figuring out, the exact reason is that: the critial section while holding the lock is too short. As a result, the overhead of the reader-writer lock becomes significant, making it perform worse than a mutex in the initial results.\nint ReadWriteLockObject::update(int dx, int dy) { std::lock_guard lock(mutex_); // Only one thread/writer can update // If this critial section takes longer, reader-writer lock is more efficient x_ += dx; y_ += dy; return 1; } If we increase the time spent while holding the lock in update function, the result is as what I expected. Now the reader-writter lock starts to outperform the mutex!\n","date":1694822400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694822400,"objectID":"0d25824f2fb8362e7e1bb612884955f6","permalink":"https://witsblog.github.io/post/030_cpp_lock/","publishdate":"2023-09-16T00:00:00Z","relpermalink":"/post/030_cpp_lock/","section":"post","summary":"I’ve long believed that reader-writer locks would outperform mutexes in scenarios with multiple readers and occasional writers. It seemes intuitive: allowing concurrent reads while ensuring exclusive writes should, in theory, optimize performance.","tags":["C/C++"],"title":"A Curious Case of Mutex vs Reader-Writer Lock !?","type":"post"},{"authors":null,"categories":null,"content":" Recently, my job has become a bit monotonous, and I find myself missing the challenges and excitement of working with low-level languages like C++. So I start to grow my interest in algorithmic trading. The blend of real-time data processing, sophisticated algorithms, and performance optimization makes this an interesting topic to study.\nIn this post, I will dive into one of the algorithmic trading engine, explore its architecture, and try to understand how things work under the hood.\n1) Architecture Overview The Engine composes of multiple components. The classes in the diagram below are not completed.\nAs a user, we write an algorithm in the Algorithm class.\nThe Engine is responsible for creating the Algorithm and all necessary threads. It then delegates the execution to AlgorithmManager.\nThe AlgorithmManager is where the main loop resides, which seems to oversee the execution and pass stuff to the Algorithm. It uses Synchronizer to pump or feed data into the Algorithm’s onData() method.\nThe AlgorithmManager’s Run() method gets an AlgorithmHandler as a parameter which has several handlers:\nTransactionHandler This defines how the transactions are processed and set the order fill information. It uses Brokerage to perform the task. It also interacts with the Algorithm’s SecurityPortfolioManager, which seems to have the functionality to simulate the fees, slippage, and other trading condition, through BrokerageModel. RealTimeHandler This triggers functions at regular or predefined intervals. ResultHandler This handles the results of the trading, generating statistics, etc. The Algorithm also has access to several entities:\nBrokerageModel SecurityManager SecurityPortfolioManager SecurityTransactionManager The Synchronizer has a DataManager which has a LiveTradingDataFeed which implements IDataFeed interface. This LiveTradingDataFeed is where the live data is coming from, and the Synchronizer provides the mechanisum to stream this data to the Algorithm’s onData() method mentioned earlier.\n2) Main Loop The main loop of an algorithmic trading engine is where the magic happens. Below is the code reference, but I will try to break it down later:\npublic void Run( // ... IAlgorithm algorithm, ISynchronizer synchronizer, ITransactionHandler transactions, IResultHandler results, IRealTimeHandler realtime, CancellationToken token, // ... ) { // ... var backtestMode = (job.Type == PacketType.BacktestNode); var methodInvokers = new Dictionary\u0026lt;Type, MethodInvoker\u0026gt;(); var marginCallFrequency = TimeSpan.FromMinutes(5); var nextMarginCallTime = DateTime.MinValue; // ... // ... var hasOnDataTradeBars = AddMethodInvoker\u0026lt;TradeBars\u0026gt;(algorithm, methodInvokers); var hasOnDataQuoteBars = AddMethodInvoker\u0026lt;QuoteBars\u0026gt;(algorithm, methodInvokers); var hasOnDataOptionChains = AddMethodInvoker\u0026lt;OptionChains\u0026gt;(algorithm, methodInvokers); var hasOnDataTicks = AddMethodInvoker\u0026lt;Ticks\u0026gt;(algorithm, methodInvokers); var hasOnDataDividends = AddMethodInvoker\u0026lt;Dividends\u0026gt;(algorithm, methodInvokers); var hasOnDataSplits = AddMethodInvoker\u0026lt;Splits\u0026gt;(algorithm, methodInvokers); var hasOnDataDelistings = AddMethodInvoker\u0026lt;Delistings\u0026gt;(algorithm, methodInvokers); var hasOnDataSymbolChangedEvents = AddMethodInvoker\u0026lt;SymbolChangedEvents\u0026gt;(algorithm, methodInvokers); // Go through the subscription types and create invokers to trigger the event handlers for each custom type... // Loop over the queues: get a data collection, then pass them all into relevent methods in the algorithm. foreach (var timeSlice in Stream(algorithm, synchronizer, results, token)) { // ... time = timeSlice.Time; algorithm.SetDateTime(time); // ... // Update the current slice before firing scheduled events or any other task algorithm.SetCurrentSlice(timeSlice.Slice); if (timeSlice.Slice.SymbolChangedEvents.Count != 0) { if (hasOnDataSymbolChangedEvents) { methodInvokers[typeof(SymbolChangedEvents)](algorithm, timeSlice.Slice.SymbolChangedEvents); } // Cancel all orders for the old symbol foreach (var symbol in timeSlice.Slice.SymbolChangedEvents.Keys) { foreach (var ticket in transactions.GetOpenOrderTickets(x =\u0026gt; x.Symbol == symbol)) { ticket.Cancel(\u0026#34;Open order cancelled on symbol changed event\u0026#34;); } } } if (timeSlice.SecurityChanges != SecurityChanges.None) { algorithm.ProcessSecurityChanges(timeSlice.SecurityChanges); realtime.OnSecuritiesChanged(timeSlice.SecurityChanges); results.OnSecuritiesChanged(timeSlice.SecurityChanges); } // Update the securities properties: first before calling user code to avoid issues with data foreach (var update in timeSlice.SecuritiesUpdateData) { var security = update.Target; security.Update(update.Data, update.DataType, update.ContainsFillForwardData); // Send market price updates to the TradeBuilder algorithm.TradeBuilder.SetMarketPrice(security.Symbol, security.Price); } // ... // Security prices got updated algorithm.Portfolio.InvalidateTotalPortfolioValue(); // Process fill models on the updated data before entering algorithm, applies to all non-market …","date":1691193600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691193600,"objectID":"8343d52118831d2a27e96e2bcea1eb73","permalink":"https://witsblog.github.io/post/025_trading_backtesting/","publishdate":"2023-08-05T00:00:00Z","relpermalink":"/post/025_trading_backtesting/","section":"post","summary":"Recently, my job has become a bit monotonous, and I find myself missing the challenges and excitement of working with low-level languages like C++. So I start to grow my interest in algorithmic trading.","tags":["Trading","C/C++"],"title":"Dissecting the Algorithmic Trading Engine","type":"post"},{"authors":null,"categories":null,"content":"\nRecently, feature stores have become essential in the MLOps stack, providing a centralized platform to serve features across training and serving enironments. In this post, I will explore how to run a self-served feature store, leveraging an open source project Feast.\nWhy? In our team, we have an application that needs to retrieve features for some ML application. At the time there was no feature store provided by the platform team, so we had to roll our own version. Although Feast’s Python SDK already provides a default implementation to interact with various backed databases for the online store, however, in our production setting, most of our backend applications are written in JVM language. So we need a JVM client library that retrieves features from the feature store. 1) Understanding the Feature Store In its simplest form, a feature store is a key-value store that stores computed features for retrieval. Feast however is more like an ecosystem around a feature store; it consists of a few important components:\nRegistry An object store of feature definitions and their metadata. SDK The library for interacting within the Feast ecosystem. The client library for ingesting and retrieving features from a feature store. Offline Store The storage that stores the ingested data, which is used for producing training datasets. It supports working with historical time-series feature. This is backed by a different storage and compute engine, for example, Spark, BigQuery, etc. Online Store The storage that sores the lastest feature value, for online, low-latency retrieval. This is usually backed by a low-latency database like Redis, Cassandra, etc. Online Serving Service / Feature Server The service that serves online features from the online store. 2) Customizing the Online Store 2.1) Default gRPC Feature Server The default feature server is implemented using the gRPC server, starting with a Google dependency injection framework Guice, that creates a io.grpc.Server instance.\npublic class ServingGuiceApplication { public static void main(String[] args) throws InterruptedException, IOException { // ... final Injector i = Guice.createInjector( new ServingServiceV2Module(), new RegistryConfigModule(), new InstrumentationConfigModule(), new ServerModule(), new ApplicationPropertiesModule(args)); Server server = i.getInstance(Server.class); server.start(); server.awaitTermination(); } } The main logic of the serving service is implemented in the OnlineServingServiceV2 class that implements the gRPC service:\nservice ServingService { // ... // Get online features synchronously. rpc GetOnlineFeatures (GetOnlineFeaturesRequest) returns (GetOnlineFeaturesResponse); } If we look at the constructor of this class, we will see that it uses an instance of OnlineRetriever to interact with the backed database:\npublic class OnlineServingServiceV2 implements ServingServiceV2 { private static final Logger log = org.slf4j.LoggerFactory.getLogger(OnlineServingServiceV2.class); private final Optional\u0026lt;Tracer\u0026gt; tracerOptional; private final OnlineRetriever retriever; private final RegistryRepository registryRepository; private final OnlineTransformationService onlineTransformationService; private final String project; // ... public OnlineServingServiceV2( OnlineRetriever retriever, RegistryRepository registryRepository, OnlineTransformationService onlineTransformationService, String project, Optional\u0026lt;Tracer\u0026gt; tracerOptional) { this.retriever = retriever; this.registryRepository = registryRepository; this.onlineTransformationService = onlineTransformationService; this.project = project; this.tracerOptional = tracerOptional; } // ... } This OnlineServingServiceV2 class is created during the dependency injection and the type of the OnlineRetriever (and therefore the backed database) is selected at runtime. If we are to use a different database such as Cassandra, ScyllaDB, etc, as a backed database for the online store, we will have to implement the code here:\npublic class ServingServiceV2Module extends AbstractModule { // ... @Provides public ServingServiceV2 registryBasedServingServiceV2( ApplicationProperties applicationProperties, RegistryRepository registryRepository, Tracer tracer) { final ServingServiceV2 servingService; final ApplicationProperties.Store store = applicationProperties.getFeast().getActiveStore(); OnlineRetriever retriever; // TODO: Support more store types, and potentially use a plugin model here. switch (store.getType()) { // ... case REDIS: RedisClientAdapter redisClient = RedisClient.create(store.getRedisConfig()); retriever = new RedisOnlineRetriever( applicationProperties.getFeast().getProject(), redisClient, new EntityKeySerializerV2( applicationProperties.getFeast().getEntityKeySerializationVersion())); break; // ... default: throw new RuntimeException( String.format( \u0026#34;Unable to identify online store type: %s for Registry Backed Serving Service\u0026#34;, store.getType())); } // ... servingService = new OnlineServingServiceV2( …","date":1684540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684540800,"objectID":"e564b39dd369f617445db1b4dfc2489f","permalink":"https://witsblog.github.io/post/023_feature_store/","publishdate":"2023-05-20T00:00:00Z","relpermalink":"/post/023_feature_store/","section":"post","summary":"Recently, feature stores have become essential in the MLOps stack, providing a centralized platform to serve features across training and serving enironments. In this post, I will explore how to run a self-served feature store, leveraging an open source project Feast.","tags":["MLOps","Data Engineering"],"title":"A Self-Served Feature Store with Feast","type":"post"},{"authors":null,"categories":null,"content":"As a software engineer at a big tech company, I usually rely on an infrastructure team to provide deployment tools for us. While convenient, this, I realized, is a missed learning opportunity.\nOne of the things that I have been curious about all along is\nHow does Kubernetes limits CPU and memory resource? How can CPU allocation even be a fraction and less than 1? Curiosity got the better of me, and I decided to explore how Kubernetes handles this task.\nRequests and Limit When we deploy our service, we can specify the resource request and limit. For example:\nresources: requests: memory: \u0026#34;256Mi\u0026#34; cpu: \u0026#34;250m\u0026#34; limits: memory: \u0026#34;768Mi\u0026#34; cpu: \u0026#34;750m\u0026#34; Basically,\nCPU\nrequest Used during the Pod scheduling. When Kubernetes scheduler selects a node for the Pod to run on, it ensures that the request does not exceed the capacity of the node. The workloads are allocated CPU time proportionally to the request. limit This sets the hard limit during each scheduling interval. If the execution time exceeds, the OS kernel will throttle. The CPU limit defines a hard ceiling on how much CPU time that the container can use. During each scheduling interval (time slice), the Linux kernel checks to see if this limit is exceeded; if so, the kernel waits before allowing that cgroup to resume execution.\nMemory\nrequest Similar to CPU request, this is used during the Pod scheduling. limit The effect of this is such that, if the container tries to allocate more memory than this limit, it will get OOM (out of memory) error. CFS Bandwidth Control The Mechanism How does Kubernetes limit the CPU?\nKubernetes limits the resource by means of the cgroup concept in the Linux kernel.\nFor CPU limit, this is done by the CFS Bandwidth Control in the Linux kernel. The bandwidth allowed for a group is specified using a quota and period.\nFor cgroup v1, these settings are located in /sys/fs/cgroup/cpu,cpuacct/, where the quota and period are in cpu.cfs_quota_us and cpu.cfs_period_us respectively.\nFor cgroup v2, these settings are in /sys/fs/cgroup/cpu.max, in the following format\n\u0026lt;quota\u0026gt; \u0026lt;preiod\u0026gt; Essentially\nWithin each given period ( ${\\mu}s$), a task group is allocated up to quota ( ${\\mu} s$) of CPU time. If the quota is fully utilized before the period ends, any additional requests for CPU time will result in those threads in the group being throttled. They won’t be able to run again until the quota is replenished in the next period. The allocated quota is divided and assigned to per-CPU run queues in slice as threads within the cgroup become runnable. This is a system wide setting in /proc/sys/kernel/sched_cfs_bandwidth_slice_us with default value = 5 ms. Unused quota is tracked globally and is refreshed at each period boundary. So how can CPU limit be a fraction? How can it be less than 1?\nLet’s visualize. Assume a task takes 125 ms to process. This is what would happen if we don’t set the CPU limit:\nIf we set CPU limit to 0.25 CPU or 250m CPU, Kubernetes would set quota $= 0.25 \\times 100 = 25$ ms. So this means that within a (default) 100 ms period, the task can use up 25 ms, and it will finish at 425 ms (instead of 125 ms, what a surprise!):\nIf we look at the cpu.stat, we would probably see:\nStatistics Value Meaning nr_periods 5 Number of intervals that have elapsed. nr_throttled 4 Number of times the group has been throttled. throttled_usec 300000 The total time duration for which the group have been throttled. From the following calculation, the throttled rate would be ~80% !\n$$throttled \\space \\% = \\frac{nr\\_throttled}{nr\\_periods}$$ More is Revealed in the Kernel Code What if the CPU limit is greater than 1? This means the quota would be greater than the period. How can it still be throttled?\nIn a real system, there are multiple CPU cores. The Linux kernel tracks the quota from the global pool rather than on a per-CPU basis. So even though the time used in each period per CPU core cannot exceed the period itself, the total sum of quota across multiple cores can be greater than the period. This can result in throttling:\nIf we look at the kernel code, we would actaully see it:\nstatic int __assign_cfs_rq_runtime(struct cfs_bandwidth *cfs_b, struct cfs_rq *cfs_rq, u64 target_runtime) { u64 min_amount, amount = 0; lockdep_assert_held(\u0026amp;cfs_b-\u0026gt;lock); min_amount = target_runtime - cfs_rq-\u0026gt;runtime_remaining; if (cfs_b-\u0026gt;quota == RUNTIME_INF) amount = min_amount; else { start_cfs_bandwidth(cfs_b); if (cfs_b-\u0026gt;runtime \u0026gt; 0) { amount = min(cfs_b-\u0026gt;runtime, min_amount); cfs_b-\u0026gt;runtime -= amount; // \u0026lt;---------- Take from the global pool cfs_b-\u0026gt;idle = 0; } } cfs_rq-\u0026gt;runtime_remaining += amount; return cfs_rq-\u0026gt;runtime_remaining \u0026gt; 0; } static int assign_cfs_rq_runtime(struct cfs_rq *cfs_rq) { struct cfs_bandwidth *cfs_b = tg_cfs_bandwidth(cfs_rq-\u0026gt;tg); int ret; raw_spin_lock(\u0026amp;cfs_b-\u0026gt;lock); // \u0026lt;---------- Lock ret = __assign_cfs_rq_runtime(cfs_b, cfs_rq, sched_cfs_bandwidth_slice()); raw_spin_unlock(\u0026amp;cfs_b-\u0026gt;lock); // \u0026lt;---------- Unlock return ret; } And from the …","date":1675468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675468800,"objectID":"69f2b0811c2a0e0f9d5fced7105c4bfc","permalink":"https://witsblog.github.io/post/021_k8s_cpu_limit/","publishdate":"2023-02-04T00:00:00Z","relpermalink":"/post/021_k8s_cpu_limit/","section":"post","summary":"As a software engineer at a big tech company, I usually rely on an infrastructure team to provide deployment tools for us. While convenient, this, I realized, is a missed learning opportunity.","tags":["Kubernetes","C/C++"],"title":"Ever Wonder How Kubernetes CPU Limit Can Be a Fraction?","type":"post"},{"authors":null,"categories":null,"content":"Cache Types 1) In-Memory Cache This uses in-memory data structure to implement a cache, such as ConcurrentHashMap in Java. If we need other functionalities such as eviction policy, then ConcurrentHashMap won’t provide a convenient way to do that. This is where a library like Caffeine comes in.\nAdvantages\nSuper fast. Disadvantages\nData is local to the service instance. Limitted by the memory available to the service instance. 2) Distributed Cache Distributed cache typically stores data in memory across multiple nodes or servers in order to scale horizontally. Examples include Redis, Couchbase, Memcached, etc.\nThis picture is not always correct though! So why not just cache in the memory of the service instance?\nAdvantages\nIf cache on service instance, the data will be wiped out every time when the service gets a deployment. Can scale cache independently. Request coalescing. If multiple instances request the same data, distributed cache can deduplicate multiple requests that would have been sent to the backing data store. Disadvantages\nMode complex setup. 3) Client-Side Caching Advantages\nCaching on the client side can help reduce server requests Disadvantages\nIt complicates the analytics as the backend will not receive the request. Will need additional logging in the client to collect metrics. Caching Strategies Read Strategy 1) Read Aside Advantages\nGreate for read-heavy loads Only requested data is written to cache Disadvantages\nCache data can be inconsistent if writes are made to database directly. Unavoidable overhead when cache miss (Can mitigate to some extent by cache warming). 2) Read Through Slight different, where the responsibility of the DB read is shifted to the cache.\nWrite Strategy 1) Write Through Advantages\nData is consistent. Disadvantages\nSlower writes; every single write goes to both cahce \u0026amp; database. Some data written to cache is never read; unnecessary cost (Can mitigate by setting TTL to reduce space). 2) Write Back Advantages\nFaster writes; writes are only made to cache initially. The writes to the DB is postponed until the modified content is about to be evicted or other cache invalidation policy. Disadvantages\nMore complex. In case of cache failure, the data may be permanently lost. 3) Write Around In this approach, the application only writes to the DB.\nMonitoring We Cache a Cache, that Caches Another Cache! References https://en.wikipedia.org/wiki/Cache_%28computing%29 https://docs.aws.amazon.com/whitepapers/latest/database-caching-strategies-using-redis/caching-patterns.html https://stackoverflow.com/questions/23355136/cache-reads-and-writes ","date":1668470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668470400,"objectID":"f4f767aaff717d12599d89ddb333024b","permalink":"https://witsblog.github.io/post/020_caif/","publishdate":"2022-11-15T00:00:00Z","relpermalink":"/post/020_caif/","section":"post","summary":"Cache Types 1) In-Memory Cache This uses in-memory data structure to implement a cache, such as ConcurrentHashMap in Java. If we need other functionalities such as eviction policy, then ConcurrentHashMap won’t provide a convenient way to do that.","tags":["Data Engineering"],"title":"Cache At its Finest","type":"post"},{"authors":null,"categories":null,"content":"In this post I will be exploring the TFX and its integration with Kubeflow Pipelines on Google AI Platform.\nThis post is kind of my summarization for my learning purpose.\n1) Dataset 2) Create Clusters 3) Understanding TFX Pipelines In order to understand TFX pipelines, we need to understand some keywords. For full tutorial, refer to TensorFlow’s article here.\nArtifact Artifacts are the output of the steps in a TFX pipeline. They can be used by subsequent steps in the pipeline.\nArtifacts must be stongly typed with an artifact type registered in the ML Metadata store. This point is not very clear yet; I need to research and will come back to expand more on this later.\nQuestions\nWhere does artifact get stored? What needs to be changed if we run the pipeline on a Cloud? Parameter Parameters are something that we can set through configuration, instead of hard coding; they are just like the hyperparameters of a ML/DL model.\nComponent Component is an implementation of the task in our pipeline. Components in TFX are composed of\nComponent specification: This defines the component’s input and output artifacts, and component’s parameters. Executor: This implements the real work of a step in the pipeline. Component interface: This packages the component specification and executor for use in a pipeline. (This is not very clear.) Questions\nWhere does the component get run? Do components run in the same environment? Same OS and same dependencies? What if each component requires different dependencies? Pipeline TensorFlow says that a TFX pipeline is a portable implementation of an ML workflow, as it can be run on different ochestrators, such as: Apache Airflow, Apache Beam, and Kubeflow Pipelines.\nFirst, we build a pipeline, which is of type tfx.orchestration.pipeline.Pipeline:\nfrom tfx.orchestration import pipeline def _create_pipeline() -\u0026gt; pipeline.Pipeline: \u0026#34;\u0026#34;\u0026#34; \u0026#34;\u0026#34;\u0026#34; pass To select a different ochestration tool, we need to import from tfx.orchestration module.\n# Airflow from tfx.orchestration.airflow.airflow_dag_runner import AirflowDagRunner from tfx.orchestration.airflow.airflow_dag_runner import AirflowPipelineConfig DAG = AirflowDagRunner(AirflowPipelineConfig()).run( _create_pipeline() ) # Kubeflow from tfx.orchestration.kubeflow import kubeflow_dag_runner kubeflow_dag_runner.KubeflowDagRunner().run( create_pipeline() ) 4) TFX Custom Components Understanding the custom components will get us far! Refer to TensorFlow’s article here.\nTFX components at runtime When a pipeline runs a TFX component, the component is executed in three phases:\nFirst, the Driver uses the component specification to retrieve the required artifacts from the metadata store and pass them into the component. Next, the Executor performs the component’s work. Then the Publisher uses the component specification and the results from the executor to store the component’s outputs in the metadata store. Types of custom components Python function-based components\nThe specification is completely defined in the Python code. The function’s arguments with type annotations describe input artifact, output artifact, and parameters. The function’s body defines the component’s executor. The component interface is dedined by adding @component decorator. @component def MyComponent( model: InputArtifact[Model], output: OutputArtifact[Model], threshold: Parameter[int] = 10 ) -\u0026gt; OutputDict(accuracy=float): \u0026#34;\u0026#34;\u0026#34; \u0026#34;\u0026#34;\u0026#34; pass Container-based components\nThis is suitable for building a component with custom runtime environment and dependencies. Fully custom components\nThis is for building a component that is not in the built-in TFX standard components. It lets us build a component by implementing a custom component specification, executor, and component interface classes. 5) Code 6) Pipeline Dashboard 7) Dataflow My Thoughts TFX seems to be built around TensorFlow. Not very sure if it’s gonna work with other DL/ML libraries without heavily modifying the TFX components. But if we are in a Google Cloud/TensorFlow ecosystem, stick with it! Unlike TFX, MLFlow seems to be more general and more open to other DL/ML libraries. References https://www.tensorflow.org/tfx/tutorials https://www.tensorflow.org/tfx/guide/mlmd ","date":1633824e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633824e3,"objectID":"32176d275374ae96460f64637ceed3ab","permalink":"https://witsblog.github.io/post/012_tfx_google_ai_platform/","publishdate":"2021-10-10T00:00:00Z","relpermalink":"/post/012_tfx_google_ai_platform/","section":"post","summary":"In this post I will be exploring the TFX and its integration with Kubeflow Pipelines on Google AI Platform.\nThis post is kind of my summarization for my learning purpose.","tags":["MLOps","Data Engineering"],"title":"Continuous Training with TFX and Kubeflow Pipelines","type":"post"},{"authors":null,"categories":null,"content":"ARV Hackathon 2021 is back with the new and even more challenging problem statements that dare you to find innovative solutions in Cyber Security and Subsea Machine Learning spaces.\nAll tech talents, start-ups, and the next generation innovators are invited to join ARV in creating the innovative technological solutions that will transform the future of Thailand and Southeast Asia.\nStay Tuned!\n","date":1633564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633564800,"objectID":"cbdb670910650eaf766037fb2070d0bd","permalink":"https://witsblog.github.io/post/011_arv_hackathon_2021/","publishdate":"2021-10-07T00:00:00Z","relpermalink":"/post/011_arv_hackathon_2021/","section":"post","summary":"ARV Hackathon 2021 is back with the new and even more challenging problem statements that dare you to find innovative solutions in Cyber Security and Subsea Machine Learning spaces.\nAll tech talents, start-ups, and the next generation innovators are invited to join ARV in creating the innovative technological solutions that will transform the future of Thailand and Southeast Asia.","tags":["Machine Learning","Robotics"],"title":"AI \u0026 Robotics Hackathon 2021","type":"post"},{"authors":null,"categories":null,"content":"","date":1625961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625961600,"objectID":"9d6bfdc5d1b316224f556ef3dab11b50","permalink":"https://witsblog.github.io/post/010_fb_ranking/","publishdate":"2021-07-11T00:00:00Z","relpermalink":"/post/010_fb_ranking/","section":"post","summary":"","tags":["Machine Learning"],"title":"Facebook’s News Feed Ranking Algorithm","type":"post"},{"authors":null,"categories":null,"content":"Anchor Boxes Data Pipeline References Mingxing Tan, Ruoming Pang, Quoc V. Le. EfficientDet: Scalable and Efficient Object Detection. CVPR 2020. ","date":1625875200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625875200,"objectID":"f47119b9570d158ea6617fc732373ef0","permalink":"https://witsblog.github.io/post/009_auto_ml/","publishdate":"2021-07-10T00:00:00Z","relpermalink":"/post/009_auto_ml/","section":"post","summary":"Anchor Boxes Data Pipeline References Mingxing Tan, Ruoming Pang, Quoc V. Le. EfficientDet: Scalable and Efficient Object Detection. CVPR 2020. ","tags":["Machine Learning"],"title":"EfficientDet: Towards Scalable Architecture in AutoML","type":"post"},{"authors":null,"categories":null,"content":"Differentiable Architecture Search\n$$ \\begin{aligned} \u0026amp;\u0026amp; \\min_{\\alpha} \u0026amp;\u0026amp;\u0026amp; \\mathcal{L}_{val} (w^{\\ast} (\\alpha), \\alpha) \\\\ \u0026amp;\u0026amp; \\text{s.t.} \u0026amp;\u0026amp;\u0026amp; w^{\\ast} (\\alpha) = \\text{argmin}_{w} \\space \\mathcal{L}_{train} (w, \\alpha) \\\\ \\end{aligned} $$ ","date":1624233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624233600,"objectID":"8bd5f7134eb3284991a435e9fb5ce7b3","permalink":"https://witsblog.github.io/post/008_darts/","publishdate":"2021-06-21T00:00:00Z","relpermalink":"/post/008_darts/","section":"post","summary":"Differentiable Architecture Search\n$$ \\begin{aligned} \u0026\u0026 \\min_{\\alpha} \u0026\u0026\u0026 \\mathcal{L}_{val} (w^{\\ast} (\\alpha), \\alpha) \\\\ \u0026\u0026 \\text{s.t.} \u0026\u0026\u0026 w^{\\ast} (\\alpha) = \\text{argmin}_{w} \\space \\mathcal{L}_{train} (w, \\alpha) \\\\ \\end{aligned} $$ ","tags":["Machine Learning"],"title":"DARTS: Differentiable Architecture Search","type":"post"},{"authors":null,"categories":null,"content":" The most successful ML projects in production (Tesla, iPhone, Amazon drones, Zipline) are where you own the entire stack. They iterate not just ML algorithms but also: 1) how to collect/label data, 2) infrastructure, 3) hardware ML models run on.\nSummarizing Andrej Karpathy’s CVPR talk, Chip Huyen highlighted that the most successful ML projects in production are those that have complete ownership of the entire stack. These projects iterate not only on ML algorithms but also on data collection and labeling, infrastructure, and the hardware on which ML models operate.\nWaymo, another major player, released its dataset in 2019, which is in TFRecord format, requiring TensorFlow for reading. This heavy dependence on TensorFlow makes the tools and data preprocessing pipeline less compatible with other frameworks. In contrast, datasets like KITTI, Lyft, TRI, and Argoverse are released in a simpler, raw format. As someone who used PyTorch more than TensorFlow, I found it difficult to inspect and debug the tf.data components when eager execution was not available inside tf.data.\nAfter a year and listening to Andrej Karpathy’s talk at CVPR 2021, I now kind of appreciate why Google’s Waymo chose to release their dataset in TFRecord format. Interestingly, the winner of the Challenge used PyTorch though.\nThe good news is… we can now use:\n# TensorFlow 2.5 tf.data.experimental.enable_debug_mode() Enough for the introduction, let’s visualize the data.\nVisualizing Camera Data Most of the code is straightforward.\nimport tensorflow as tf import matplotlib.pyplot as plt import matplotlib.patches as patches # Replace FILENAME with tfrecord file dataset = tf.data.TFRecordDataset(FILENAME, compression_type=\u0026#39;\u0026#39;) for data in dataset: frame = open_dataset.Frame() frame.ParseFromString(bytearray(data.numpy())) plt.figure() # Draw the camera labels. count = 0 for camera_image in frame.images: for camera_labels in frame.camera_labels: # Ignore camera labels that do not correspond to this camera. if camera_labels.name != camera_image.name: continue count += 1 ax = plt.subplot(2, 3, count) # Iterate over the individual labels. for label in camera_labels.labels: # Draw the object bounding box. ax.add_patch(patches.Rectangle( xy=(label.box.center_x - 0.5 * label.box.length, label.box.center_y - 0.5 * label.box.width), width=label.box.length, height=label.box.width, linewidth=1, edgecolor=\u0026#39;red\u0026#39;, facecolor=\u0026#39;none\u0026#39;)) # Show the camera image. plt.imshow(tf.image.decode_jpeg(camera_image.image)) plt.title(camera_image.name)) plt.grid(False) plt.axis(\u0026#39;off\u0026#39;) plt.show() plt.close() The following shows some of the dataset.\nDataset Statistics 3D Labels 2D Labels ","date":1624233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624233600,"objectID":"d5c6754e02a4cb56fa72fc04d0c12842","permalink":"https://witsblog.github.io/post/007_explore_waymo_perception/","publishdate":"2021-06-21T00:00:00Z","relpermalink":"/post/007_explore_waymo_perception/","section":"post","summary":"The most successful ML projects in production (Tesla, iPhone, Amazon drones, Zipline) are where you own the entire stack. They iterate not just ML algorithms but also: 1) how to collect/label data, 2) infrastructure, 3) hardware ML models run on.","tags":["Machine Learning","Machine Learning"],"title":"Waymo Open Dataset","type":"post"},{"authors":null,"categories":null,"content":"","date":1615507200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615507200,"objectID":"6bd880b2758050a99875f90a344de9c6","permalink":"https://witsblog.github.io/post/006_cuda_basic/","publishdate":"2021-03-12T00:00:00Z","relpermalink":"/post/006_cuda_basic/","section":"post","summary":"","tags":["Computer Vision","C/C++"],"title":"Accelerating Performance with CUDA!","type":"post"},{"authors":null,"categories":null,"content":"Introduction The Oil and Gas industry is one of the most lucrative industries that has a very high operating cost. Cutting costs is therefore a major priority when it comes to this business. In this post, I share some of the mahcine learning (or data science, if you will) applications that I have worked on.\n","date":1611532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611532800,"objectID":"a6ea3ef94dbe12585625aaacd7143dec","permalink":"https://witsblog.github.io/post/005_data_sci_pttep_arv/","publishdate":"2021-01-25T00:00:00Z","relpermalink":"/post/005_data_sci_pttep_arv/","section":"post","summary":"Introduction The Oil and Gas industry is one of the most lucrative industries that has a very high operating cost. Cutting costs is therefore a major priority when it comes to this business.","tags":["Robotics","Machine Learning"],"title":"Data Science \u0026 Machine Learning In Oil And Gas Industry","type":"post"},{"authors":null,"categories":null,"content":"","date":1609718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609718400,"objectID":"ed92176040f153580434e386b1621b78","permalink":"https://witsblog.github.io/post/004_sonar_sim/","publishdate":"2021-01-04T00:00:00Z","relpermalink":"/post/004_sonar_sim/","section":"post","summary":"","tags":["Robotics","Computer Vision","CUDA"],"title":"Custom Sonar Simulation in Gazebo","type":"post"},{"authors":null,"categories":null,"content":" “We stand on the brink of a technological revolution. Soon, few of us will own our own automobiles and instead will get around in driverless electric vehicles that we summon with the touch of an app. We will be liberated from driving, prevent over 90% of car crashes, provide freedom of mobility to the elderly and disabled, and decrease our dependence on fossil fuels.” — The Quest to Build the Driverless Car\nThe same applies to oil and gas industry. Although robotic technologies have entered the oil and gas industry for around some time, the quest to build the autonomous underwater vehicle must go on!\nIn this post, I will briefly write about the kind of the things we do at our R\u0026amp;D team. (Please note that I cannot write all the details and so I have skipped some parts.)\nA System What do we need in order to build an autonomous underwater vehicle and its system?\nHardware Software Navigation software Perception algorithms Planning algorithms Control algorithms Simulation platform Data analytics software All the teams (software, electrical, and mechanical) collaboratively design the robot. The physical aspect of the robot is mainly designed by a mechanical engineer team where they need to consider things such as the dynamic model, hydrodynamic model, robot mechanisms, and etc. The electrical engineer team is the ones who design and lay out electrical circuits connecting all components to a system. The software team mostly look at the high level aspect of the robot such as what sensors, what algorithms, how to communicate with the vessel, how many computing units, how to store logging data, and the list goes on.\nHardware Navigation Software IMU dead reckoning SLAM Map building Perception Algorithms Perception algorithms are probably the key to intelligent autonomous vehicles. At ARV, we have developed several algorithms, including but not limited to 2D object detection, 3D object detection, point cloud-related algorithms, etc., in order to tackle the challenges we encountered in subsea robotics.\nWe have also developed several machine learning and deep learning models for automatic pipeline inspection as well. These are used both in online (real-time) and offline (data analytics software).\nPlanning Algorithms Way point planning Optimal path planning Control Algorithms Simulation Platform This is probably the testbed of our robotics software development. We use Gazebo as a simulator for realistic simulation, with some custom-implemented sensor plugins that we developed for our own use.\nOf course, these custom plugins should run very fast for the simulation to run smoothly, so the algorihtms must be hevily optimized. For example, the custom sonar plugin was implemented in CUDA to speed things up.\nData Analytics Software The collected data when the robot operates at the seabed must be analyzed in some way. We build our web application where customers can log in to see the analyzed data (as well as raw data) and the generated report.\n","date":1609718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609718400,"objectID":"28764f42a733e158e16381b9c4af432d","permalink":"https://witsblog.github.io/post/003_the_quest_to_build_auv/","publishdate":"2021-01-04T00:00:00Z","relpermalink":"/post/003_the_quest_to_build_auv/","section":"post","summary":"“We stand on the brink of a technological revolution. Soon, few of us will own our own automobiles and instead will get around in driverless electric vehicles that we summon with the touch of an app.","tags":["Robotics"],"title":"The Quest to Build an Autonomous Underwater Vehicle","type":"post"},{"authors":null,"categories":null,"content":"1. Introduction 2. Model Implementation 3. Initial Results 3.1 Single Class Detection Simple Scenes Currently the model is trained on a single class: car. For the following result, green indicates the ground truth labels, and light blue indicates the predicted results.\nIn a simple scene, the model seems to recognize all the car objects:\nHarder Since the model is trained using only the top view LIDAR data, it is reasonable that the model can miss the cases where thr LIDAR point cloud of the object is sparse:\nEasy Mistake However, the model still misses some obvious detection, such as in the following scene. Here, the front car in the very middle doesn’t get detected.\nWhy Top View? What I think the top view (or bird’s eye view) approach can do well is that: It can detect the objects which are occluded in the front camera view. If we look at the following image, the car on the very right of the image is largely occluded:\nHowever, viewing the point cloud from the top, these 2 cars are clearly separated in the space, and therefore the model can easily detect the targeted objects:\n3.2 Multi-Class Detection 4. Final Results 5. My Thoughts 6. References H. Su, S. Maji, E. Kalogerakis, and E. G. Learned-Miller. Multi-view convolutional neural networks for 3d shaperecognition ICCV, 2015 Bin Yang, Wenjie Luo, and Raquel Urtasun. PIXOR: Real-time 3d object detection from point clouds CVPR, 2018 ","date":1572393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572393600,"objectID":"e4ba43a9ce562a37b47f33cb8ad285cc","permalink":"https://witsblog.github.io/post/002_3d_object_detection/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/post/002_3d_object_detection/","section":"post","summary":"1. Introduction 2. Model Implementation 3. Initial Results 3.1 Single Class Detection Simple Scenes Currently the model is trained on a single class: car. For the following result, green indicates the ground truth labels, and light blue indicates the predicted results.","tags":["Machine Learning"],"title":"Real-time 3D Object Detection from Point Clouds","type":"post"},{"authors":null,"categories":null,"content":"Introduction This is the first-ever post of my blog; so I will give it a try. This post is about things that I went through when I tried to implement a simple monocular visual odometry from scratch. For a programming language, I choose MATLAB because it is easy-to-use and fast for prototyping a project.\nDisclaimer: This is not a state-of-the-art implementation. This simply serves the purpose of learning.\nThe Problem To give a general idea, visual odometry (VO) is an algorithm that aims to recover the path incrementally, by using the visual input from cameras, and hence the name. It can be considered as a sequential structure from motion, as opposed to hierarchical structure from motion. Imagine a robot or an agent, attached with a calibrated camera $C$, moves through an environment and receives the image continuously. The images $I_k, I_{k-1}$ are taken at different time steps $k$ and $k-1$, which corresponds to the camera pose $C_k$ and $C_{k-1}$ respectively. The task of VO is basically to retrieve the transformation matrix $$T = \\left[R \\lvert t \\right]$$ that relates two camera poses, and concatenate all the transformaitons $T_k$ to get the current camera pose:\n$$ C_{t} = T_{t,t-1}C_{t-1}$$ Getting Things Up \u0026amp; Running I first have an initialization function vo_initialize.m that takes two image frames, establishing keypoint correspondences between these two frames using KLT feature tracker, estimating relative camera pose, and finally triangulating an initial 3D point cloud landmarks. I admit that these may sound lacking of excitement (as they are something that is well understood in the computer vision community), but they are not easy to implement from scratch in a single sit.\nFeature Detection This is a simple plementation of Harris corner detector. For each pixel $(u,v)$, we calculate a score\n$$R = det(A_{u,v}) - {\\lambda}trace^2(A_{u,v})$$ where\n$$ A_{u,v} = \\begin{bmatrix} \\sum{I^2_{x}} \u0026amp; \\sum{I_{x}I_{y}}\\\\ \\sum{I_{x}I_{y}} \u0026amp; \\sum{I^2_{y}} \\end{bmatrix} $$ and $I_x, I_y$ are the image gradients in $x$ and $y$ direction respectively.\nI_x = conv2(img, [-1 0 1; -2 0 2; -1 0 1], \u0026#39;valid\u0026#39;); I_y = conv2(img, [-1 -2 -1; 0 0 0; 1 2 1], \u0026#39;valid\u0026#39;); I_xx = double(I_x.^2); I_yy = double(I_y.^2); I_xy = double(I_x.*I_y); I_xx_sum = conv2(I_xx, ones(patch_size), \u0026#39;valid\u0026#39;); I_yy_sum = conv2(I_yy, ones(patch_size), \u0026#39;valid\u0026#39;); I_xy_sum = conv2(I_xy, ones(patch_size), \u0026#39;valid\u0026#39;); pad_size = floor((patch_size+1)/2); scores = (I_xx_sum.*I_yy_sum - I_xy_sum.^2) - lambda*(I_xx_sum + I_yy_sum).^2; scores(scores \u0026lt; 0) = 0; scores = padarray(scores, [pad_size pad_size]); After calculating the score, we simply select $k$ keypoints with highest scores (with non-maximum suppression).\nscores_pad = padarray(scores, [r r]); score_size = size(scores_pad); keypoints = zeros(2, k); for i = 1:k [~, idx] = max(scores_pad, [], \u0026#39;all\u0026#39;, \u0026#39;linear\u0026#39;); [row, col] = ind2sub(score_size, idx); keypoints(:, i) = [row; col] - r; scores_pad(row-r:row+r, col-r:col+r) = 0; end KLT Feature Tracker …\nPose Estimation …\nTriangulation …\nThe result of vo_initialize.m seems reasonable. Good to go!\nProblems from Previous Implementation …\nEstimate World Camera Pose …\nBundle Adjustment Bundle adjustment is a very cool concept. To put it simply, it is an optimization algorithm used to refine the estimated trajectory.\nIn this implementation, a motion-only bundle adjustment is implemented, which optimizes only the camera orientation $R$ and position $t$. This implies that\nResults Putting it all together, the vo_initialize.m function initializes the VO pipeline, creating initial 3D point landmarks, extracting initial keypoints, and estimating the initial pose of the camera. The vo_process.m sequentially extracting and tracking image features from an image frame, across frames, and simultaneously estimating the pose of the camera. Bundle adjustment is also implemented to refine the estimated pose at each step. Lastly, new 3D points are regularly created as the number of currently tracked keypoints is shrinking over time. The following is the final result.\nFrom the video, it is obvious that this is not a state-of-the-art implementation. There are various components that are not implemented. As we can see, the estimated trajectory starts to deviate from the ground truth after some time, due to the scale drift–a common problem in monocular VO. The estimated trajetory also wiggles slightly, probaly due to the fact that the full bundle adjustment is not implemented. And the most importantly, I did not try to implement a loop closure.\nReflections The task of implementing VO from scratch may sound lacking of excitement. I believe that the conventional pipeline of VO and SLAM is something that is already well-understood in the computer vision community. What I realize is that academic papers usually have missing steps that are left for the readers to figure out. Here, I tried to connect those steps and the result stands as a self-assesment of my understanding.\n","date":1570233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570233600,"objectID":"89d8541ea0902255d1cdc0e0a36192ab","permalink":"https://witsblog.github.io/post/001_visual_odometry/","publishdate":"2019-10-05T00:00:00Z","relpermalink":"/post/001_visual_odometry/","section":"post","summary":"Introduction This is the first-ever post of my blog; so I will give it a try. This post is about things that I went through when I tried to implement a simple monocular visual odometry from scratch.","tags":["Robotics","Computer Vision"],"title":"Visual Odometry Implementation from Scratch","type":"post"},{"authors":null,"categories":null,"content":"This is a project where we used reinforcement learning to train the robot to collect balls in a simple environment. The robot is a 4-Mecanum wheeled robot equipped with a camera and a 2D LiDAR sensor. The algorithms were implemented on Intel NUC and Nvidia Jetson TX2 board.\nThis is my attempt at re-writing a write-up because a lot of recruiters ask me how the project was done and I sometimes forget (it was done in 2018).\nOptimal Policy and Optimal Value Functions Bellman optimality equation\nFor optimal value function $v_{*}$:\n$$ \\begin{aligned} v_{*}(s) \u0026amp;= \\max_{a} E \\left[ R_{t+1} + \\gamma v_{*}(S_{t+1}) \\vert S_{t}=s, A_{t}=a \\right] \\\\ \u0026amp;= \\max_{a} \\sum_{s\u0026#39;,r} p(s\u0026#39;,r \\vert s,a) \\left[ r + \\gamma v_{*}(s\u0026#39;) \\right] \\end{aligned} $$ For optimal action-value function $q_{*}$:\n$$ \\begin{aligned} q_{*}(s,a) \u0026amp;= E \\left[ R_{t+1} + \\gamma \\max_{a\u0026#39;} q_{*}(S_{t+1}, a\u0026#39;) \\vert S_{t} = s, A_{t} = a \\right] \\\\ \u0026amp;= \\sum_{s\u0026#39;,r} p(s\u0026#39;,r \\vert s,a) \\left[ r + \\gamma \\max_{a\u0026#39;} q_{*}(s\u0026#39;,a\u0026#39;) \\right] \\end{aligned} $$ Monte Carlo Methods Monte Carlo methods only require a sample of states, actions, and rewards from interaction between the agent and the environment. It is model-free; the probability distributions such as state-transition $p(s\u0026#39; \\vert s,a)$ need not to be known.\nQ-Learning $$ Q(s,a) \\leftarrow (1-\\alpha)Q(s,a) + \\alpha \\left[ r + \\gamma \\max_{a\u0026#39;} Q(s\u0026#39;,a\u0026#39;) \\right] $$ Initialize Q(s, a) Start with state \u0026#34;s\u0026#34; Loop: Select action \u0026#34;a\u0026#34; with e-greedy Execute action \u0026#34;a\u0026#34;, receive immediate reward \u0026#34;r\u0026#34; and go to state \u0026#34;s\u0026#39;\u0026#34; Q(s, a) = Q(s, a) + alpha*[r + gamma * max{Q(s\u0026#39;, a\u0026#39;)} - Q(s, a)] But what if the number of $(s,a)$ pairs are very big? Then it is not practical to keep the table $Q$ for every pair of $(s,a)$. Instead, we could maintain $Q(s,a)$ as a parameterized function. This is where the neural network comes into play.\nQ-Network Training\nWe define the loss as:\n$$ L(\\theta) = \\left( \\left( r + \\gamma \\max_{a\u0026#39;} {Q(s\u0026#39;, a\u0026#39; | \\theta }) \\right) - Q(s,a|\\theta) \\right)^2 $$ Our objective is to find weight $\\theta$ of the network to minimize the loss:\n$$ \\min_{\\theta} L(\\theta) = \\min_{\\theta} \\left[ \\left( r + \\gamma \\max_{a\u0026#39;} {Q(s\u0026#39;, a\u0026#39; | \\theta }) - Q(s,a|\\theta) \\right)^2 \\right] $$ where $r$ is the immediate reward that we observe and the term $r + \\gamma \\max_{a\u0026#39;} {Q(s\u0026#39;, a\u0026#39; | \\theta })$ is the approximated target.\nConvergence\nHowever, using a neural network to represent the action-value function tends to be unstable due to:\nCorrelations between samples Non-stationary targets How does DeepMind solve this issue?\nExperience replay Separated networks Go deeper (added by myself) Experience Replay Separated Networks $$ L(\\theta) = \\left( \\left( r + \\gamma \\max_{a\u0026#39;} {Q(s\u0026#39;, a\u0026#39; | \\theta^{-} }) \\right) - Q(s,a|\\theta) \\right)^2 $$ Gallery References Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015). ","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"3c1241fed2e2d76a3623317d0c5bd7b8","permalink":"https://witsblog.github.io/project/00_robot/","publishdate":"2018-08-01T00:00:00Z","relpermalink":"/project/00_robot/","section":"project","summary":"This is a project where we used reinforcement learning to train the robot to collect balls in a simple environment. The robot is a 4-Mecanum wheeled robot equipped with a camera and a 2D LiDAR sensor.","tags":["Robotics","Reinforcement Learning"],"title":"Autonomous Ball-Collecting Robot using Reinforcement Learning","type":"project"}]